{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVpPmr7mIByM",
        "outputId": "7719ef37-506e-4472-905c-b4416e2328ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb  7 03:24:02 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "torch: 2.9.0+cu126\n",
            "cuda: True\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y30g_pw3IEGY"
      },
      "outputs": [],
      "source": [
        "!pip -q install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2webl-sSJADu"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # upload kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXT3_TjYJIHO"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp bdd100k-seg-6cls-api.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -la ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZIdq215JWXn"
      },
      "outputs": [],
      "source": [
        "DATASET_SLUG = \"manhdung4869/bdd100k-seg-6class-custom\"\n",
        "\n",
        "!kaggle datasets download -d {DATASET_SLUG} -p /content --force\n",
        "!ls -lh /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrpfgH_pJu3h"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "zip_files = glob.glob(\"/content/*.zip\")\n",
        "print(\"zip_files:\", zip_files)\n",
        "\n",
        "for z in zip_files:\n",
        "    !unzip -q -o \"$z\" -d /content/dataset\n",
        "\n",
        "!find /content/dataset -maxdepth 2 -type d | head -n 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmqC3mDyJzaI"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATA_ROOT = Path(\"/content/dataset/bdd_seg_6cls_final\")\n",
        "assert DATA_ROOT.exists(), f\"DATA_ROOT not found: {DATA_ROOT}\"\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "\n",
        "def count_files(p: Path, exts):\n",
        "    if not p.exists(): return 0\n",
        "    return sum(1 for f in p.iterdir() if f.is_file() and f.suffix.lower() in exts)\n",
        "\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\"}\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    ni = count_files(DATA_ROOT/\"images\"/sp, IMG_EXTS)\n",
        "    nm = count_files(DATA_ROOT/\"masks\"/sp, {\".png\"})\n",
        "    print(f\"{sp:>5}: images={ni} masks={nm}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCyjiXkeJ-M_"
      },
      "outputs": [],
      "source": [
        "!pip -q install pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHYOxaIrKBjP"
      },
      "outputs": [],
      "source": [
        "import random, time, gc\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "class BDDSeg6Cls(Dataset):\n",
        "    def __init__(self, root: Path, split: str, img_size: int = 512, augment: bool = False):\n",
        "        self.root = Path(root)\n",
        "        self.split = split\n",
        "        self.img_dir = self.root / \"images\" / split\n",
        "        self.msk_dir = self.root / \"masks\" / split\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "\n",
        "        self.images = sorted([p for p in self.img_dir.iterdir()\n",
        "                              if p.is_file() and p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\"}])\n",
        "        self.mask_index = {p.stem.lower(): p for p in self.msk_dir.glob(\"*.png\")}\n",
        "\n",
        "        # keep only paired\n",
        "        self.images = [p for p in self.images if p.stem.lower() in self.mask_index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        msk_path = self.mask_index[img_path.stem.lower()]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(msk_path)\n",
        "\n",
        "        # resize (no caching)\n",
        "        img = TF.resize(img, [self.img_size, self.img_size], interpolation=TF.InterpolationMode.BILINEAR)\n",
        "        mask = TF.resize(mask, [self.img_size, self.img_size], interpolation=TF.InterpolationMode.NEAREST)\n",
        "\n",
        "        # light aug\n",
        "        if self.augment:\n",
        "            if random.random() < 0.5:\n",
        "                img = TF.hflip(img)\n",
        "                mask = TF.hflip(mask)\n",
        "\n",
        "        img_t = TF.to_tensor(img)\n",
        "        img_t = TF.normalize(img_t, mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "\n",
        "        mask_t = torch.from_numpy(np.array(mask, dtype=np.uint8)).long()\n",
        "        return img_t, mask_t\n",
        "\n",
        "IMG_SIZE = 512   # RAM/GPU-safe\n",
        "BATCH = 4        # safe for T4 / P100\n",
        "NW = 0           # RAM-safe\n",
        "\n",
        "train_ds = BDDSeg6Cls(DATA_ROOT, \"train\", img_size=IMG_SIZE, augment=True)\n",
        "val_ds   = BDDSeg6Cls(DATA_ROOT, \"val\",   img_size=IMG_SIZE, augment=False)\n",
        "test_ds  = BDDSeg6Cls(DATA_ROOT, \"test\",  img_size=IMG_SIZE, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=NW, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=NW, pin_memory=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=NW, pin_memory=False)\n",
        "\n",
        "print(\"sizes:\", len(train_ds), len(val_ds), len(test_ds))\n",
        "\n",
        "# mask sanity\n",
        "p = next((DATA_ROOT/\"masks\"/\"train\").glob(\"*.png\"))\n",
        "print(\"mask unique sample:\", np.unique(np.array(Image.open(p)))[:50])\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOxJhodGKEeR"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 6\n",
        "IGNORE = 255\n",
        "\n",
        "model = torchvision.models.segmentation.deeplabv3_resnet50(\n",
        "    weights=None,\n",
        "    weights_backbone=\"DEFAULT\",\n",
        "    num_classes=NUM_CLASSES\n",
        ").to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=IGNORE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "EPOCHS = 35\n",
        "total_iters = EPOCHS * len(train_loader)\n",
        "base_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "def poly_lr(iter_idx, total_iters, base_lr, power=0.9):\n",
        "    return base_lr * ((1 - iter_idx / total_iters) ** power)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "print(\"iters/epoch:\", len(train_loader), \"total_iters:\", total_iters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz1JQF9DKLzP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def fast_confusion_matrix(pred, target, num_classes, ignore_index=255):\n",
        "    mask = target != ignore_index\n",
        "    pred = pred[mask]\n",
        "    target = target[mask]\n",
        "    if pred.numel() == 0:\n",
        "        return torch.zeros((num_classes, num_classes), dtype=torch.int64, device=pred.device)\n",
        "    k = (target * num_classes + pred).to(torch.int64)\n",
        "    cm = torch.bincount(k, minlength=num_classes*num_classes).reshape(num_classes, num_classes)\n",
        "    return cm\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, num_classes=6, ignore_index=255):\n",
        "    model.eval()\n",
        "    cm_total = torch.zeros((num_classes, num_classes), dtype=torch.int64, device=DEVICE)\n",
        "    loss_sum = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for imgs, masks in loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        masks = masks.to(DEVICE)\n",
        "\n",
        "        out = model(imgs)[\"out\"]\n",
        "        loss = criterion(out, masks)\n",
        "        loss_sum += loss.item()\n",
        "        n_batches += 1\n",
        "\n",
        "        pred = out.argmax(1)\n",
        "        cm_total += fast_confusion_matrix(pred, masks, num_classes, ignore_index)\n",
        "\n",
        "    tp = torch.diag(cm_total).float()\n",
        "    fp = cm_total.sum(0).float() - tp\n",
        "    fn = cm_total.sum(1).float() - tp\n",
        "    denom = tp + fp + fn\n",
        "    iou = torch.where(denom > 0, tp / denom, torch.zeros_like(denom))\n",
        "    miou = iou.mean().item()\n",
        "\n",
        "    return (loss_sum / max(n_batches,1)), miou, iou.detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzFL2C5lF1Cc"
      },
      "outputs": [],
      "source": [
        "DRIVE_DIR = \"/content/drive/MyDrive/deeplab6_runs\"\n",
        "import os, torch\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, global_iter, best_miou, path):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"global_iter\": global_iter,\n",
        "        \"best_miou\": best_miou,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"num_classes\": NUM_CLASSES\n",
        "    }, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsERSSu2KOWu"
      },
      "outputs": [],
      "source": [
        "!pip -q install tqdm\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import time, os\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Mount Drive (idempotent) ---\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# --- Local + Drive dirs ---\n",
        "RUN_DIR = Path(\"/content/runs_deeplab6\")\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/deeplab6_runs\")  # Ä‘á»•i tÃªn folder náº¿u muá»‘n\n",
        "DRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "best_path = RUN_DIR / \"best.pt\"\n",
        "last_path = RUN_DIR / \"last.pt\"\n",
        "drive_best = DRIVE_DIR / \"best.pt\"\n",
        "drive_last = DRIVE_DIR / \"last.pt\"\n",
        "\n",
        "def save_ckpt(path: Path, epoch: int, best_miou: float, global_iter: int):\n",
        "    # full checkpoint to allow true resume\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"global_iter\": global_iter,\n",
        "        \"best_miou\": best_miou,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"num_classes\": NUM_CLASSES\n",
        "    }, path)\n",
        "\n",
        "best_miou = -1.0\n",
        "global_iter = 0\n",
        "LOG_EVERY = 50  # in log má»—i 50 step\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "\n",
        "    pbar = tqdm(enumerate(train_loader, start=1), total=len(train_loader), leave=True)\n",
        "    running = 0.0\n",
        "\n",
        "    for step, (imgs, masks) in pbar:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        masks = masks.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        lr = poly_lr(global_iter, total_iters, base_lr)\n",
        "        for pg in optimizer.param_groups:\n",
        "            pg[\"lr\"] = lr\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            out = model(imgs)[\"out\"]\n",
        "            loss = criterion(out, masks)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loss_item = loss.item()\n",
        "        running += loss_item\n",
        "        global_iter += 1\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        pbar.set_postfix({\"lr\": f\"{lr:.2e}\", \"loss\": f\"{loss_item:.4f}\", \"avg\": f\"{running/step:.4f}\"})\n",
        "\n",
        "        if step % LOG_EVERY == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            it_per_sec = step / max(elapsed, 1e-6)\n",
        "            eta_sec = (len(train_loader) - step) / max(it_per_sec, 1e-6)\n",
        "            print(f\"[epoch {epoch:02d}] step {step:04d}/{len(train_loader)} \"\n",
        "                  f\"lr={lr:.2e} loss={loss_item:.4f} avg={running/step:.4f} ETA={eta_sec/60:.1f}m\")\n",
        "\n",
        "    train_loss = running / max(len(train_loader), 1)\n",
        "\n",
        "    # epoch-end eval\n",
        "    val_loss, val_miou, _ = evaluate(model, val_loader, NUM_CLASSES, IGNORE)\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch:02d}/{EPOCHS} DONE | {dt/60:.1f} min | \"\n",
        "          f\"train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_mIoU {val_miou:.4f}\")\n",
        "\n",
        "    # --- ALWAYS save LAST (local + drive) ---\n",
        "    save_ckpt(last_path, epoch, best_miou, global_iter)\n",
        "    os.system(f'cp \"{last_path}\" \"{drive_last}\"')\n",
        "\n",
        "    # --- Save BEST (local + drive) if improved ---\n",
        "    if val_miou > best_miou:\n",
        "        best_miou = val_miou\n",
        "        save_ckpt(best_path, epoch, best_miou, global_iter)\n",
        "        os.system(f'cp \"{best_path}\" \"{drive_best}\"')\n",
        "        print(\" saved BEST ->\", best_path, \" | synced ->\", drive_best)\n",
        "    else:\n",
        "        print(\" synced LAST ->\", drive_last)\n",
        "\n",
        "print(\"Best val mIoU:\", best_miou)\n",
        "print(\"Local best:\", best_path)\n",
        "print(\"Drive best:\", drive_best)\n",
        "print(\"Drive last:\", drive_last)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfBHgdbzm2_4"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from google.colab import drive\n",
        "import os, time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1) Mount Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "RUN_DIR = Path(\"/content/runs_deeplab6\")\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/deeplab6_runs\")\n",
        "DRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive_last = DRIVE_DIR / \"last.pt\"\n",
        "drive_best = DRIVE_DIR / \"best.pt\"\n",
        "\n",
        "# 2) Chá»n checkpoint Ä‘á»ƒ resume (Æ°u tiÃªn last)\n",
        "ckpt_path = drive_last if drive_last.exists() else drive_best\n",
        "assert ckpt_path.exists(), f\"KhÃ´ng tháº¥y checkpoint á»Ÿ Drive: {drive_last} hoáº·c {drive_best}\"\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
        "\n",
        "for st in optimizer.state.values():\n",
        "    for k, v in st.items():\n",
        "        if torch.is_tensor(v):\n",
        "            st[k] = v.to(DEVICE)\n",
        "\n",
        "start_epoch = int(ckpt[\"epoch\"]) + 1\n",
        "global_iter = int(ckpt.get(\"global_iter\", 0))\n",
        "best_miou = float(ckpt.get(\"best_miou\", -1.0))\n",
        "\n",
        "#sanity check config\n",
        "print(\"Resume from:\", ckpt_path)\n",
        "print(\"start_epoch:\", start_epoch, \"| global_iter:\", global_iter, \"| best_miou:\", best_miou)\n",
        "print(\"ckpt img_size:\", ckpt.get(\"img_size\"), \"| current IMG_SIZE:\", IMG_SIZE)\n",
        "print(\"ckpt num_classes:\", ckpt.get(\"num_classes\"), \"| current NUM_CLASSES:\", NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6-VfJhJm6Nk"
      },
      "outputs": [],
      "source": [
        "best_path = RUN_DIR / \"best.pt\"\n",
        "last_path = RUN_DIR / \"last.pt\"\n",
        "drive_best_out = DRIVE_DIR / \"best.pt\"\n",
        "drive_last_out = DRIVE_DIR / \"last.pt\"\n",
        "\n",
        "LOG_EVERY = 50\n",
        "\n",
        "def save_ckpt(path: Path, epoch: int, best_miou: float, global_iter: int):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"global_iter\": global_iter,\n",
        "        \"best_miou\": best_miou,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"num_classes\": NUM_CLASSES\n",
        "    }, path)\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS + 1):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    running = 0.0\n",
        "\n",
        "    pbar = tqdm(enumerate(train_loader, start=1), total=len(train_loader), leave=True)\n",
        "\n",
        "    for step, (imgs, masks) in pbar:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        masks = masks.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        lr = poly_lr(global_iter, total_iters, base_lr)\n",
        "        for pg in optimizer.param_groups:\n",
        "            pg[\"lr\"] = lr\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            out = model(imgs)[\"out\"]\n",
        "            loss = criterion(out, masks)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loss_item = float(loss.item())\n",
        "        running += loss_item\n",
        "        global_iter += 1\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        pbar.set_postfix({\"lr\": f\"{lr:.2e}\", \"loss\": f\"{loss_item:.4f}\", \"avg\": f\"{running/step:.4f}\"})\n",
        "\n",
        "        if step % LOG_EVERY == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            it_per_sec = step / max(elapsed, 1e-6)\n",
        "            eta_sec = (len(train_loader) - step) / max(it_per_sec, 1e-6)\n",
        "            print(f\"[epoch {epoch:02d}] step {step:04d}/{len(train_loader)} \"\n",
        "                  f\"lr={lr:.2e} loss={loss_item:.4f} avg={running/step:.4f} ETA={eta_sec/60:.1f}m\")\n",
        "\n",
        "    train_loss = running / max(len(train_loader), 1)\n",
        "\n",
        "    val_loss, val_miou, _ = evaluate(model, val_loader, NUM_CLASSES, IGNORE)\n",
        "    dt = time.time() - t0\n",
        "    print(f\"\\nEpoch {epoch:02d}/{EPOCHS} DONE | {dt/60:.1f} min | \"\n",
        "          f\"train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_mIoU {val_miou:.4f}\")\n",
        "\n",
        "    # ALWAYS save LAST (local + drive)\n",
        "    save_ckpt(last_path, epoch, best_miou, global_iter)\n",
        "    os.system(f'cp \"{last_path}\" \"{drive_last_out}\"')\n",
        "\n",
        "    # Save BEST if improved\n",
        "    if val_miou > best_miou:\n",
        "        best_miou = val_miou\n",
        "        save_ckpt(best_path, epoch, best_miou, global_iter)\n",
        "        os.system(f'cp \"{best_path}\" \"{drive_best_out}\"')\n",
        "        print(\"saved BEST ->\", best_path, \"| synced ->\", drive_best_out)\n",
        "    else:\n",
        "        print(\"synced LAST ->\", drive_last_out)\n",
        "\n",
        "print(\"Best val mIoU:\", best_miou)\n",
        "print(\"Drive best:\", drive_best_out)\n",
        "print(\"Drive last:\", drive_last_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-5KCBVa3hkq"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# CELL â€” Early Stopping (patience) + Auto Fine-tune from BEST\n",
        "# Criterion: val_mIoU (maximize)\n",
        "# =========================\n",
        "\n",
        "from pathlib import Path\n",
        "import os, time\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- dirs (same as yours) ---\n",
        "RUN_DIR = Path(\"/content/runs_deeplab6\"); RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/deeplab6_runs\"); DRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "local_last = RUN_DIR / \"last.pt\"\n",
        "local_best = RUN_DIR / \"best.pt\"\n",
        "drive_last = DRIVE_DIR / \"last.pt\"\n",
        "drive_best = DRIVE_DIR / \"best.pt\"\n",
        "\n",
        "def save_ckpt(path: Path, epoch: int, best_miou: float, global_iter: int):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"global_iter\": global_iter,\n",
        "        \"best_miou\": best_miou,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"num_classes\": NUM_CLASSES\n",
        "    }, path)\n",
        "\n",
        "# -------------------------\n",
        "# Early stopping config\n",
        "# -------------------------\n",
        "PATIENCE = 5          # stop if no improvement for 5 epochs\n",
        "MIN_DELTA = 1e-4      # require improvement > min_delta\n",
        "EARLY_STOP_MIN_EPOCH = 8  # don't early stop too early\n",
        "\n",
        "# -------------------------\n",
        "# Fine-tune config\n",
        "# -------------------------\n",
        "DO_FINE_TUNE = True\n",
        "FT_EPOCHS = 8\n",
        "FT_LR_SCALE = 0.25    # base_lr * 0.25\n",
        "FT_PATIENCE = 3\n",
        "FT_MIN_DELTA = 1e-4\n",
        "\n",
        "LOG_EVERY = 50\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def set_optimizer_lr(new_lr: float):\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = new_lr\n",
        "\n",
        "def load_ckpt_into_all(ckpt_path: Path):\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    model.load_state_dict(ckpt[\"model_state\"])\n",
        "    optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "    scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
        "    # move optimizer state to device\n",
        "    for st in optimizer.state.values():\n",
        "        for k, v in st.items():\n",
        "            if torch.is_tensor(v):\n",
        "                st[k] = v.to(DEVICE)\n",
        "    return ckpt\n",
        "\n",
        "# -------------------------\n",
        "# Train one epoch\n",
        "# -------------------------\n",
        "def train_one_epoch(epoch: int, global_iter: int, total_iters: int, base_lr: float):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    running = 0.0\n",
        "\n",
        "    pbar = tqdm(enumerate(train_loader, start=1), total=len(train_loader), leave=True)\n",
        "    for step, (imgs, masks) in pbar:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        masks = masks.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        lr = poly_lr(global_iter, total_iters, base_lr)\n",
        "        set_optimizer_lr(lr)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            out = model(imgs)[\"out\"]\n",
        "            loss = criterion(out, masks)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loss_item = float(loss.item())\n",
        "        running += loss_item\n",
        "        global_iter += 1\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        pbar.set_postfix({\"lr\": f\"{lr:.2e}\", \"loss\": f\"{loss_item:.4f}\", \"avg\": f\"{running/step:.4f}\"})\n",
        "\n",
        "        if step % LOG_EVERY == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            it_per_sec = step / max(elapsed, 1e-6)\n",
        "            eta_sec = (len(train_loader) - step) / max(it_per_sec, 1e-6)\n",
        "            print(f\"[epoch {epoch:02d}] step {step:04d}/{len(train_loader)} \"\n",
        "                  f\"lr={lr:.2e} loss={loss_item:.4f} avg={running/step:.4f} ETA={eta_sec/60:.1f}m\")\n",
        "\n",
        "    train_loss = running / max(len(train_loader), 1)\n",
        "    return train_loss, global_iter, (time.time() - t0)\n",
        "\n",
        "# =========================\n",
        "# MAIN TRAIN with Early Stop\n",
        "no_improve = 0\n",
        "best_epoch = None\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS + 1):\n",
        "    train_loss, global_iter, dt_train = train_one_epoch(epoch, global_iter, total_iters, base_lr)\n",
        "\n",
        "    val_loss, val_miou, _ = evaluate(model, val_loader, NUM_CLASSES, IGNORE)\n",
        "    print(f\"\\nEpoch {epoch:02d}/{EPOCHS} DONE | {(dt_train)/60:.1f} min | \"\n",
        "          f\"train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_mIoU {val_miou:.4f}\")\n",
        "\n",
        "    # always save LAST\n",
        "    save_ckpt(local_last, epoch, best_miou, global_iter)\n",
        "    os.system(f'cp \"{local_last}\" \"{drive_last}\"')\n",
        "    print(\"synced LAST ->\", drive_last)\n",
        "\n",
        "    # check improvement\n",
        "    improved = (val_miou > best_miou + MIN_DELTA)\n",
        "    if improved:\n",
        "        best_miou = float(val_miou)\n",
        "        best_epoch = epoch\n",
        "        no_improve = 0\n",
        "        save_ckpt(local_best, epoch, best_miou, global_iter)\n",
        "        os.system(f'cp \"{local_best}\" \"{drive_best}\"')\n",
        "        print(\"saved BEST ->\", local_best, \"| synced ->\", drive_best)\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        print(f\"no_improve={no_improve}/{PATIENCE} (best_mIoU={best_miou:.4f} at epoch {best_epoch})\")\n",
        "\n",
        "    # early stop condition\n",
        "    if epoch >= EARLY_STOP_MIN_EPOCH and no_improve >= PATIENCE:\n",
        "        print(f\"EARLY STOP at epoch {epoch} (no improvement for {PATIENCE} epochs).\")\n",
        "        break\n",
        "\n",
        "print(\"Train phase best_mIoU:\", best_miou, \"| best_epoch:\", best_epoch)\n",
        "\n",
        "# =========================\n",
        "if DO_FINE_TUNE:\n",
        "    assert drive_best.exists(), \"KhÃ´ng tháº¥y best.pt trÃªn Drive Ä‘á»ƒ fine-tune.\"\n",
        "    print(\"ðŸ” Fine-tune from BEST:\", drive_best)\n",
        "\n",
        "    ckpt = load_ckpt_into_all(drive_best)\n",
        "    ft_start_epoch = int(ckpt[\"epoch\"]) + 1\n",
        "    ft_best = float(ckpt.get(\"best_miou\", best_miou))\n",
        "    ft_no_improve = 0\n",
        "\n",
        "    ft_base_lr = base_lr * FT_LR_SCALE\n",
        "    print(f\"Fine-tune: base_lr {base_lr:.2e} -> {ft_base_lr:.2e} | epochs={FT_EPOCHS}\")\n",
        "\n",
        "    ft_total_iters = FT_EPOCHS * len(train_loader)\n",
        "    ft_global_iter = 0  # reset schedule for fine-tune\n",
        "\n",
        "    for i in range(FT_EPOCHS):\n",
        "        epoch_ft = ft_start_epoch + i\n",
        "        train_loss, ft_global_iter, dt_train = train_one_epoch(epoch_ft, ft_global_iter, ft_total_iters, ft_base_lr)\n",
        "\n",
        "        val_loss, val_miou, _ = evaluate(model, val_loader, NUM_CLASSES, IGNORE)\n",
        "        print(f\"\\n[FT] Epoch {epoch_ft:02d} DONE | {(dt_train)/60:.1f} min | \"\n",
        "              f\"train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_mIoU {val_miou:.4f}\")\n",
        "\n",
        "        save_ckpt(local_last, epoch_ft, ft_best, ft_global_iter)\n",
        "        os.system(f'cp \"{local_last}\" \"{drive_last}\"')\n",
        "\n",
        "        improved = (val_miou > ft_best + FT_MIN_DELTA)\n",
        "        if improved:\n",
        "            ft_best = float(val_miou)\n",
        "            ft_no_improve = 0\n",
        "            save_ckpt(local_best, epoch_ft, ft_best, ft_global_iter)\n",
        "            os.system(f'cp \"{local_best}\" \"{drive_best}\"')\n",
        "            print(\"[FT] saved BEST ->\", drive_best)\n",
        "        else:\n",
        "            ft_no_improve += 1\n",
        "            print(f\"[FT] no_improve={ft_no_improve}/{FT_PATIENCE} (best_mIoU={ft_best:.4f})\")\n",
        "\n",
        "        if ft_no_improve >= FT_PATIENCE:\n",
        "            print(f\"EARLY STOP fine-tune (no improvement for {FT_PATIENCE} epochs).\")\n",
        "            break\n",
        "\n",
        "    print(\"Fine-tune best_mIoU:\", ft_best)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
